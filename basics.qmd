---
title: Kernels and BO in Julia
author: David Bindel
date: 2025-06-19
jupyter: julia-1.11
format:
  html:
    toc: true
  pdf:
    toc: true
    monofont: "Fira Code"
---

```{julia}
#| echo: false
#| output: false
using LinearAlgebra
using Plots
using Random
using StatsFuns
using SpecialFunctions
using Optim

include("_src/sample.jl")
include("_src/fdchecks.jl")
```

::: {.content-hidden unless-format="html"}
$$
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\bbR}{\mathbb{R}}
$$
:::

::: {.content-hidden unless-format="pdf"}
```{=latex}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\bbR}{\mathbb{R}}
```
:::

# Introduction

Given that there are several of us working on kernel methods and
Bayesian optimization at the moment, it seems worth giving a
bare-bones treatment of the computational pieces.  We will make some
effort to be at least a little efficient and to show off how to use
the Julia language effectively, but will not worry too much about all
the details, nor will we try to make this as efficient as at all
possible.

The basic moving pieces are:

- Choosing an initial sample
- Approximating a function with a kernel
- Choosing kernel hyperparameters
- Gradients of posterior means and variances
- Some standard acquisition functions
- Optimization of acquisition functions
- Additional numerical tricks

{{< include _src/sample.qmd >}}

{{< include _src/fdchecks.qmd >}}

{{< include _kfuns.qmd >}}

{{< include _kmats.qmd >}}

{{< include _gpp.qmd >}}

{{< include _hypers.qmd >}}

{{< include _acquisition.qmd >}}

{{< include _bo_demo.qmd >}}
